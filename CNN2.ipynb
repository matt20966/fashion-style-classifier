{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "d6a989a5-03b4-4e35-8562-55c15e68536d",
      "cell_type": "code",
      "source": "# This is the second CNN where I implement different methods to try achieve the highest accuracy possible\n\nimport pandas as pd \nimport numpy as np \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout \nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array \nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split \nimport pandas as pd \nfrom google.colab import drive \n\n# Connecting to my google drive in order to access files, in this case styles.csv \ndrive.mount('/content/drive') \ncsv_path = '/content/drive/My Drive/styles.csv' \ndf = pd.read_csv(csv_path, on_bad_lines='skip') \n\n# Filter for three categories \nclothing_categories = ['Casual', 'Formal', 'Smart Casual'] \ndf_filtered = df[df['usage'].isin(clothing_categories)] \ndf_filtered = df_filtered.reset_index(drop=True) \n\n# checking the rows in the dataframe \nprint(f\"Number of rows in filtered dataframe: {len(df_filtered)}\") \nprint(df_filtered.head()) ",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e8c29fbf-faa6-4c50-8a0f-60ddc6d23da2",
      "cell_type": "code",
      "source": "import os\n\n# Setting image dimensions\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nNUM_CHANNELS = 3\n\nX = []\ny = []\n\n# File path to the folder containing all images\nfile_path = '/content/drive/My Drive/images'\n\n# Get's all images in the id range\ndf_subset = df_filtered[\n   (df_filtered['id'] >= 0) &\n   (df_filtered['id'] <= 50000)\n]\n\n# Goes through the folder outputting how many images it has processed as it runs, also displays any images it didn't find\nfor idx, row in df_subset.iterrows():\n    img_id = str(row['id'])\n\n    try:\n        img_path = os.path.join(file_path, f\"{img_id}.jpg\")\n\n        if not os.path.exists(img_path):\n            print(f\"Image {img_id} not found.\")\n            continue\n\n        img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n        img_array = img_to_array(img)\n\n        img_array = img_array / 255.0\n\n        X.append(img_array)\n        y.append(row['usage'])\n\n        # Every 1000 images processed output message\n        if len(X) % 1000 == 0:\n            print(f\"Processed {len(X)} images\")\n\n    except Exception as e:\n        print(f\"Error loading image {img_id}: {str(e)}\")\n\nX = np.array(X)\ny = np.array(y)\n\nprint(\"\\nFinal dataset shape:\")\nprint(\"Images shape:\", X.shape)\nprint(\"Labels shape:\", y.shape)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c6884647-deb1-4cb0-9af4-38c5d6b8d2df",
      "cell_type": "code",
      "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import LabelEncoder \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \nfrom tensorflow.keras.optimizers import Adam \n\n# Encode labels (convert text labels to numbers) \nlabel_encoder = LabelEncoder() \ny_encoded = label_encoder.fit_transform(y) \n\n# Split the data \nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42) \n\n# Define data augmentation for the training data \ntrain_datagen = ImageDataGenerator( \n    rescale=1./255,          # Normalizes pixel values to 0, 1 \n    rotation_range=40,       # Random rotation of up to 40 degrees \n    width_shift_range=0.2,   # Random horizontal shift of the image\n    height_shift_range=0.2,  # Random vertical shift of the image\n    zoom_range=0.2,          # Random zoom \n    horizontal_flip=True,    # Randomly flip images horizontally \n    shear_range=0.2,         # Random shear transformation \n    fill_mode='nearest'      # Fill any missing pixels after transformations \n) \n\n# Define validation data augmentation  \ntest_datagen = ImageDataGenerator(rescale=1./255) \n\n# Applies data augmentation to training data \ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=32) \n\n# Applies rescaling to test data \ntest_generator = test_datagen.flow(X_test, y_test, batch_size=32) \n\n# Loads the VGG16 model for transfer learning\n#base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n#base_model.trainable = False\n#model = Sequential([\n    #base_model,              # Pre-trained VGG16 base model\n    #Flatten(),               \n   # Dense(64, activation='relu'),  \n  #  Dropout(0.5),           \n #   Dense(3, activation='softmax') \n#])\n\n# Relu is used as it introduces non-linearity, allowing the model to learn more complex patterns\nmodel = Sequential([ \n    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)), \n    MaxPooling2D(2, 2), \n    Conv2D(64, (3, 3), activation='relu'), \n    MaxPooling2D(2, 2), \n    Conv2D(64, (3, 3), activation='relu'), \n    MaxPooling2D(2, 2), \n    Flatten(), # Flattens the output to a 1D array to connect to dense layers\n    Dense(64, activation='relu'), \n    Dropout(0.7), # Dropout layer to prevent overfitting\n\n    Dense(3, activation='softmax') # Output layer\n]) \n\n \n\n# Compiles the model \n# Used Adam optimizer as it adapts the learning rate for each parameter making it efficent for large datasets or when dealing\n# with large amounts of parameters. The faster convergance of Adam allowed for faster testing.\nmodel.compile(optimizer=Adam(), \n    loss='sparse_categorical_crossentropy', # Good option for multi-class classification it measures the difference between the predicted class \n    metrics=['accuracy'])                   # probabilities and the true class labels\n\n# Prints a summary of the model\nmodel.summary() ",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ca13f749-8231-47b7-b1b0-78370821d6e6",
      "cell_type": "code",
      "source": "# I chose 50 epochs to make sure I was certain I was letting the model go through enough iterations the model only needs ~15 before overfitting occurs\nhistory = model.fit( \n    X_train, \n    y_train, \n    epochs=50, \n    batch_size=32, \n    validation_split=0.2 \n) \n\ntest_loss, test_accuracy = model.evaluate(X_test, y_test) \nprint(f\"\\nTest accuracy: {test_accuracy:.4f}\") \n\nmodel.save('fashion_classifier.h5') \n\nimport pickle \nwith open('label_encoder.pkl', 'wb') as f: \n    pickle.dump(label_encoder, f) ",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "105316fa-3f6b-4712-af5c-a94b30fa02af",
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt \n\n# Plots the training and validation accuracy \nplt.plot(history.history['accuracy'], label='Training Accuracy') \nplt.plot(history.history['val_accuracy'], label='Validation Accuracy') \nplt.title('Model Accuracy') \nplt.xlabel('Epochs') \nplt.ylabel('Accuracy') \nplt.legend() \nplt.grid(True) \nplt.show() \n\n# Evaluates the model printing the results\ntest_loss, test_accuracy = model.evaluate(X_test, y_test) \nprint(f\"\\nTest accuracy: {test_accuracy:.4f}\") ",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}